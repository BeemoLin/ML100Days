{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd\nfrom sklearn.metrics import accuracy_score \nfrom sklearn.model_selection import cross_val_score\n\nimport os\nprint(os.listdir(\"../input/data-science-london-scikit-learn\"))","execution_count":26,"outputs":[{"output_type":"stream","text":"['test.csv', 'train.csv', 'trainLabels.csv']\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data = pd.read_csv('../input/data-science-london-scikit-learn/train.csv',header = None)\ntrain_labels = pd.read_csv('../input/data-science-london-scikit-learn/trainLabels.csv',header = None)\ntest_data =  pd.read_csv('../input/data-science-london-scikit-learn/test.csv',header = None)","execution_count":27,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('train_data', train_data.shape)\nprint('test_data', test_data.shape)\nprint('train_labels', train_labels.shape)\ntrain_data.head()","execution_count":28,"outputs":[{"output_type":"stream","text":"train_data (1000, 40)\ntest_data (9000, 40)\ntrain_labels (1000, 1)\n","name":"stdout"},{"output_type":"execute_result","execution_count":28,"data":{"text/plain":"         0         1         2         3         4         5         6   \\\n0  0.299403 -1.226624  1.498425 -1.176150  5.289853  0.208297  2.404498   \n1 -1.174176  0.332157  0.949919 -1.285328  2.199061 -0.151268 -0.427039   \n2  1.192222 -0.414371  0.067054 -2.233568  3.658881  0.089007  0.203439   \n3  1.573270 -0.580318 -0.866332 -0.603812  3.125716  0.870321 -0.161992   \n4 -0.613071 -0.644204  1.112558 -0.032397  3.490142 -0.011935  1.443521   \n\n         7         8         9   ...        30        31        32        33  \\\n0  1.594506 -0.051608  0.663234  ... -0.850465 -0.622990 -1.833057  0.293024   \n1  2.619246 -0.765884 -0.093780  ... -0.819750  0.012037  2.038836  0.468579   \n2 -4.219054 -1.184919 -1.240310  ... -0.604501  0.750054 -3.360521  0.856988   \n3  4.499666  1.038741 -1.092716  ...  1.022959  1.275598 -3.480110 -1.065252   \n4 -4.290282 -1.761308  0.807652  ...  0.513906 -1.803473  0.518579 -0.205029   \n\n         34        35        36        37        38        39  \n0  3.552681  0.717611  3.305972 -2.715559 -2.682409  0.101050  \n1 -0.517657  0.422326  0.803699  1.213219  1.382932 -1.817761  \n2 -2.751451 -1.582735  1.672246  0.656438 -0.932473  2.987436  \n3  2.153133  1.563539  2.767117  0.215748  0.619645  1.883397  \n4 -4.744566 -1.520015  1.830651  0.870772 -1.894609  0.408332  \n\n[5 rows x 40 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>30</th>\n      <th>31</th>\n      <th>32</th>\n      <th>33</th>\n      <th>34</th>\n      <th>35</th>\n      <th>36</th>\n      <th>37</th>\n      <th>38</th>\n      <th>39</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>0.299403</td>\n      <td>-1.226624</td>\n      <td>1.498425</td>\n      <td>-1.176150</td>\n      <td>5.289853</td>\n      <td>0.208297</td>\n      <td>2.404498</td>\n      <td>1.594506</td>\n      <td>-0.051608</td>\n      <td>0.663234</td>\n      <td>...</td>\n      <td>-0.850465</td>\n      <td>-0.622990</td>\n      <td>-1.833057</td>\n      <td>0.293024</td>\n      <td>3.552681</td>\n      <td>0.717611</td>\n      <td>3.305972</td>\n      <td>-2.715559</td>\n      <td>-2.682409</td>\n      <td>0.101050</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>-1.174176</td>\n      <td>0.332157</td>\n      <td>0.949919</td>\n      <td>-1.285328</td>\n      <td>2.199061</td>\n      <td>-0.151268</td>\n      <td>-0.427039</td>\n      <td>2.619246</td>\n      <td>-0.765884</td>\n      <td>-0.093780</td>\n      <td>...</td>\n      <td>-0.819750</td>\n      <td>0.012037</td>\n      <td>2.038836</td>\n      <td>0.468579</td>\n      <td>-0.517657</td>\n      <td>0.422326</td>\n      <td>0.803699</td>\n      <td>1.213219</td>\n      <td>1.382932</td>\n      <td>-1.817761</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>1.192222</td>\n      <td>-0.414371</td>\n      <td>0.067054</td>\n      <td>-2.233568</td>\n      <td>3.658881</td>\n      <td>0.089007</td>\n      <td>0.203439</td>\n      <td>-4.219054</td>\n      <td>-1.184919</td>\n      <td>-1.240310</td>\n      <td>...</td>\n      <td>-0.604501</td>\n      <td>0.750054</td>\n      <td>-3.360521</td>\n      <td>0.856988</td>\n      <td>-2.751451</td>\n      <td>-1.582735</td>\n      <td>1.672246</td>\n      <td>0.656438</td>\n      <td>-0.932473</td>\n      <td>2.987436</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>1.573270</td>\n      <td>-0.580318</td>\n      <td>-0.866332</td>\n      <td>-0.603812</td>\n      <td>3.125716</td>\n      <td>0.870321</td>\n      <td>-0.161992</td>\n      <td>4.499666</td>\n      <td>1.038741</td>\n      <td>-1.092716</td>\n      <td>...</td>\n      <td>1.022959</td>\n      <td>1.275598</td>\n      <td>-3.480110</td>\n      <td>-1.065252</td>\n      <td>2.153133</td>\n      <td>1.563539</td>\n      <td>2.767117</td>\n      <td>0.215748</td>\n      <td>0.619645</td>\n      <td>1.883397</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>-0.613071</td>\n      <td>-0.644204</td>\n      <td>1.112558</td>\n      <td>-0.032397</td>\n      <td>3.490142</td>\n      <td>-0.011935</td>\n      <td>1.443521</td>\n      <td>-4.290282</td>\n      <td>-1.761308</td>\n      <td>0.807652</td>\n      <td>...</td>\n      <td>0.513906</td>\n      <td>-1.803473</td>\n      <td>0.518579</td>\n      <td>-0.205029</td>\n      <td>-4.744566</td>\n      <td>-1.520015</td>\n      <td>1.830651</td>\n      <td>0.870772</td>\n      <td>-1.894609</td>\n      <td>0.408332</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 40 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.describe()","execution_count":29,"outputs":[{"output_type":"execute_result","execution_count":29,"data":{"text/plain":"                0            1            2            3            4   \\\ncount  1000.000000  1000.000000  1000.000000  1000.000000  1000.000000   \nmean      0.025596    -0.024526    -0.024088    -0.002271     1.092329   \nstd       1.008282     1.016298     0.979109     0.970575     4.538834   \nmin      -3.365711    -3.492086    -2.695602    -3.460471   -16.421901   \n25%      -0.669010    -0.693937    -0.698830    -0.617557    -1.801997   \n50%       0.027895    -0.033194     0.008145     0.002327     0.862818   \n75%       0.762520     0.682753     0.661434     0.640743     3.843172   \nmax       3.326246     3.583870     2.546507     3.088738    17.565345   \n\n                5            6            7            8            9   ...  \\\ncount  1000.000000  1000.000000  1000.000000  1000.000000  1000.000000  ...   \nmean     -0.006250     0.497342    -0.037883     0.026391    -0.003597  ...   \nstd       0.989128     2.118819     2.232256     1.001064     1.013520  ...   \nmin      -3.041250    -7.224761    -6.509084    -3.145588    -2.749812  ...   \n25%      -0.732265    -0.838619    -1.604037    -0.677562    -0.682220  ...   \n50%       0.027041     0.582321     0.018809     0.022092    -0.036110  ...   \n75%       0.671456     1.913664     1.438304     0.741310     0.665364  ...   \nmax       3.102997     7.592666     7.130097     3.145258     3.919426  ...   \n\n                30           31           32           33           34  \\\ncount  1000.000000  1000.000000  1000.000000  1000.000000  1000.000000   \nmean      0.030651     0.022951    -0.542491    -0.011608    -0.483507   \nstd       1.011645     1.001375     2.239939     1.022456     2.121281   \nmin      -3.379194    -2.971125    -7.840890    -2.999564    -7.124105   \n25%      -0.659457    -0.696032    -2.121943    -0.664550    -1.879247   \n50%       0.049416     0.049778    -0.568262    -0.028097    -0.493575   \n75%       0.747031     0.699917     0.939348     0.651374     1.005795   \nmax       2.844792     3.688047     7.160379     3.353631     6.005818   \n\n                35           36           37           38           39  \ncount  1000.000000  1000.000000  1000.000000  1000.000000  1000.000000  \nmean      0.033371     0.567185     0.006849    -0.892659     0.609451  \nstd       1.007044     2.227876     0.997635     2.022022     2.045439  \nmin      -2.952358    -5.452254    -3.473913    -8.051722    -7.799086  \n25%      -0.642861    -1.059786    -0.691162    -2.220126    -0.565041  \n50%       0.037732     0.455474     0.038284    -0.855470     0.779944  \n75%       0.691800     2.122157     0.693535     0.388698     1.992193  \nmax       3.420561     6.603499     3.492548     5.774120     6.803984  \n\n[8 rows x 40 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>30</th>\n      <th>31</th>\n      <th>32</th>\n      <th>33</th>\n      <th>34</th>\n      <th>35</th>\n      <th>36</th>\n      <th>37</th>\n      <th>38</th>\n      <th>39</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>count</td>\n      <td>1000.000000</td>\n      <td>1000.000000</td>\n      <td>1000.000000</td>\n      <td>1000.000000</td>\n      <td>1000.000000</td>\n      <td>1000.000000</td>\n      <td>1000.000000</td>\n      <td>1000.000000</td>\n      <td>1000.000000</td>\n      <td>1000.000000</td>\n      <td>...</td>\n      <td>1000.000000</td>\n      <td>1000.000000</td>\n      <td>1000.000000</td>\n      <td>1000.000000</td>\n      <td>1000.000000</td>\n      <td>1000.000000</td>\n      <td>1000.000000</td>\n      <td>1000.000000</td>\n      <td>1000.000000</td>\n      <td>1000.000000</td>\n    </tr>\n    <tr>\n      <td>mean</td>\n      <td>0.025596</td>\n      <td>-0.024526</td>\n      <td>-0.024088</td>\n      <td>-0.002271</td>\n      <td>1.092329</td>\n      <td>-0.006250</td>\n      <td>0.497342</td>\n      <td>-0.037883</td>\n      <td>0.026391</td>\n      <td>-0.003597</td>\n      <td>...</td>\n      <td>0.030651</td>\n      <td>0.022951</td>\n      <td>-0.542491</td>\n      <td>-0.011608</td>\n      <td>-0.483507</td>\n      <td>0.033371</td>\n      <td>0.567185</td>\n      <td>0.006849</td>\n      <td>-0.892659</td>\n      <td>0.609451</td>\n    </tr>\n    <tr>\n      <td>std</td>\n      <td>1.008282</td>\n      <td>1.016298</td>\n      <td>0.979109</td>\n      <td>0.970575</td>\n      <td>4.538834</td>\n      <td>0.989128</td>\n      <td>2.118819</td>\n      <td>2.232256</td>\n      <td>1.001064</td>\n      <td>1.013520</td>\n      <td>...</td>\n      <td>1.011645</td>\n      <td>1.001375</td>\n      <td>2.239939</td>\n      <td>1.022456</td>\n      <td>2.121281</td>\n      <td>1.007044</td>\n      <td>2.227876</td>\n      <td>0.997635</td>\n      <td>2.022022</td>\n      <td>2.045439</td>\n    </tr>\n    <tr>\n      <td>min</td>\n      <td>-3.365711</td>\n      <td>-3.492086</td>\n      <td>-2.695602</td>\n      <td>-3.460471</td>\n      <td>-16.421901</td>\n      <td>-3.041250</td>\n      <td>-7.224761</td>\n      <td>-6.509084</td>\n      <td>-3.145588</td>\n      <td>-2.749812</td>\n      <td>...</td>\n      <td>-3.379194</td>\n      <td>-2.971125</td>\n      <td>-7.840890</td>\n      <td>-2.999564</td>\n      <td>-7.124105</td>\n      <td>-2.952358</td>\n      <td>-5.452254</td>\n      <td>-3.473913</td>\n      <td>-8.051722</td>\n      <td>-7.799086</td>\n    </tr>\n    <tr>\n      <td>25%</td>\n      <td>-0.669010</td>\n      <td>-0.693937</td>\n      <td>-0.698830</td>\n      <td>-0.617557</td>\n      <td>-1.801997</td>\n      <td>-0.732265</td>\n      <td>-0.838619</td>\n      <td>-1.604037</td>\n      <td>-0.677562</td>\n      <td>-0.682220</td>\n      <td>...</td>\n      <td>-0.659457</td>\n      <td>-0.696032</td>\n      <td>-2.121943</td>\n      <td>-0.664550</td>\n      <td>-1.879247</td>\n      <td>-0.642861</td>\n      <td>-1.059786</td>\n      <td>-0.691162</td>\n      <td>-2.220126</td>\n      <td>-0.565041</td>\n    </tr>\n    <tr>\n      <td>50%</td>\n      <td>0.027895</td>\n      <td>-0.033194</td>\n      <td>0.008145</td>\n      <td>0.002327</td>\n      <td>0.862818</td>\n      <td>0.027041</td>\n      <td>0.582321</td>\n      <td>0.018809</td>\n      <td>0.022092</td>\n      <td>-0.036110</td>\n      <td>...</td>\n      <td>0.049416</td>\n      <td>0.049778</td>\n      <td>-0.568262</td>\n      <td>-0.028097</td>\n      <td>-0.493575</td>\n      <td>0.037732</td>\n      <td>0.455474</td>\n      <td>0.038284</td>\n      <td>-0.855470</td>\n      <td>0.779944</td>\n    </tr>\n    <tr>\n      <td>75%</td>\n      <td>0.762520</td>\n      <td>0.682753</td>\n      <td>0.661434</td>\n      <td>0.640743</td>\n      <td>3.843172</td>\n      <td>0.671456</td>\n      <td>1.913664</td>\n      <td>1.438304</td>\n      <td>0.741310</td>\n      <td>0.665364</td>\n      <td>...</td>\n      <td>0.747031</td>\n      <td>0.699917</td>\n      <td>0.939348</td>\n      <td>0.651374</td>\n      <td>1.005795</td>\n      <td>0.691800</td>\n      <td>2.122157</td>\n      <td>0.693535</td>\n      <td>0.388698</td>\n      <td>1.992193</td>\n    </tr>\n    <tr>\n      <td>max</td>\n      <td>3.326246</td>\n      <td>3.583870</td>\n      <td>2.546507</td>\n      <td>3.088738</td>\n      <td>17.565345</td>\n      <td>3.102997</td>\n      <td>7.592666</td>\n      <td>7.130097</td>\n      <td>3.145258</td>\n      <td>3.919426</td>\n      <td>...</td>\n      <td>2.844792</td>\n      <td>3.688047</td>\n      <td>7.160379</td>\n      <td>3.353631</td>\n      <td>6.005818</td>\n      <td>3.420561</td>\n      <td>6.603499</td>\n      <td>3.492548</td>\n      <td>5.774120</td>\n      <td>6.803984</td>\n    </tr>\n  </tbody>\n</table>\n<p>8 rows × 40 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"PRE-PROCESSING"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Train-Test Split\nfrom sklearn.model_selection import train_test_split\n\nx_train, x_test, y_train, y_test = train_test_split(train_data, train_labels, test_size=0.33, random_state=42)\n\nprint('X_train', x_train.shape)\nprint('X_test', x_test.shape)\nprint('y_train', y_train.shape)\nprint('y_test', y_test.shape)","execution_count":30,"outputs":[{"output_type":"stream","text":"X_train (670, 40)\nX_test (330, 40)\ny_train (670, 1)\ny_test (330, 1)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn import metrics\nlr_model = LogisticRegression(solver='lbfgs', multi_class='auto')\nlr_model.fit(x_train, y_train)\ny_pred = lr_model.predict(x_test)\nmetrics.accuracy_score(y_test, y_pred)","execution_count":31,"outputs":[{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n","name":"stderr"},{"output_type":"execute_result","execution_count":31,"data":{"text/plain":"0.8303030303030303"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 使用Logistic Regression之前需要先對資料做特徵縮放\nfrom sklearn.preprocessing import MinMaxScaler\nMMEncoder = MinMaxScaler()\nmm_train_data = MMEncoder.fit_transform(train_data)","execution_count":32,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#LOGISTIC REGRESSION\nfrom sklearn.linear_model import LogisticRegression\n\n# lr_model = LogisticRegression(solver = 'lbfgs', multi_class='auto')\n# lr_model.fit(x_train,y_train.values.ravel())\n# lr_predicted = lr_model.predict(x_test)\n# print('Logistic Regression',accuracy_score(y_test, lr_predicted))\nprint('Logistic Regression',cross_val_score(lr_model, mm_train_data, train_labels.values.ravel(), cv=10).mean())","execution_count":33,"outputs":[{"output_type":"stream","text":"Logistic Regression 0.8210000000000001\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Read the test data\ntest_data\n# Treat the test data in the same way as training data. In this case, pull same columns.\n# test_X = test[predictor_cols]\n# Use the model to make predictions\npredicted_result = lr_model.predict(test_data)\n# We will look at the predicted prices to ensure we have something sensible.\nprint(predicted_result)\n\nmy_submission = pd.DataFrame({'Id': test_data.index+1, 'Solution': predicted_result})\n# # you could use any filename. We choose submission here\nmy_submission.to_csv('submission.csv', index=False)\n\nmy_submission\n\n","execution_count":49,"outputs":[{"output_type":"stream","text":"[1 0 0 ... 1 0 1]\n","name":"stdout"},{"output_type":"execute_result","execution_count":49,"data":{"text/plain":"        Id  Solution\n0        1         1\n1        2         0\n2        3         0\n3        4         0\n4        5         0\n...    ...       ...\n8995  8996         1\n8996  8997         1\n8997  8998         1\n8998  8999         0\n8999  9000         1\n\n[9000 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Id</th>\n      <th>Solution</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>3</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>4</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>5</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <td>8995</td>\n      <td>8996</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <td>8996</td>\n      <td>8997</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <td>8997</td>\n      <td>8998</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <td>8998</td>\n      <td>8999</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <td>8999</td>\n      <td>9000</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>9000 rows × 2 columns</p>\n</div>"},"metadata":{}}]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"nbformat":4,"nbformat_minor":1}