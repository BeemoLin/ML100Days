{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Work\n",
    "1. 請比較 SGD optimizer 不同的 momentum 及使用 nesterov 與否的表現"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import keras\n",
    "\n",
    "# 本作業可以不需使用 GPU, 將 GPU 設定為 \"無\" (若想使用可自行開啟)\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = keras.datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 資料前處理\n",
    "def preproc_x(x, flatten=True):\n",
    "    x = x / 255.\n",
    "    if flatten:\n",
    "        x = x.reshape((len(x), -1))\n",
    "    return x\n",
    "\n",
    "def preproc_y(y, num_classes=10):\n",
    "    if y.shape[-1] == 1:\n",
    "        y = keras.utils.to_categorical(y, num_classes)\n",
    "    return y    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = train\n",
    "x_test, y_test = test\n",
    "\n",
    "# 資料前處理 - X 標準化\n",
    "x_train = preproc_x(x_train)\n",
    "x_test = preproc_x(x_test)\n",
    "\n",
    "# 資料前處理 -Y 轉成 onehot\n",
    "y_train = preproc_y(y_train)\n",
    "y_test = preproc_y(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Code Here\n",
    "建立你的神經網路\n",
    "\"\"\"\n",
    "\n",
    "def build_mlp(input_shape, output_units=10, num_neurons=[512, 256, 128]):\n",
    "    input_layer = keras.layers.Input(input_shape)\n",
    "    \n",
    "    for i, n_units in enumerate(num_neurons):\n",
    "        if i == 0:\n",
    "            x = keras.layers.Dense(units=n_units, activation=\"relu\", name=\"hidden_layer\"+str(i+1))(input_layer)\n",
    "        else:\n",
    "            x = keras.layers.Dense(units=n_units, activation=\"relu\", name=\"hidden_layer\"+str(i+1))(x)\n",
    "    \n",
    "    out = keras.layers.Dense(units=output_units, activation=\"softmax\", name=\"output\")(x)\n",
    "    \n",
    "    model = keras.models.Model(inputs=[input_layer], outputs=[out])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Code Here\n",
    "設定超參數\n",
    "\"\"\"\n",
    "LEARNING_RATE = [1e-1, 1e-2, 1e-3, 1e-4, 1e-5]\n",
    "EPOCHS = 50\n",
    "BATCH_SIZE = 256\n",
    "MOMENTUM = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment with LR = 0.100000\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,738,890\n",
      "Trainable params: 1,738,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 7s 131us/step - loss: 2.1822 - accuracy: 0.1795 - val_loss: 1.9639 - val_accuracy: 0.2442\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 6s 124us/step - loss: 1.9016 - accuracy: 0.2937 - val_loss: 2.0211 - val_accuracy: 0.2926\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 6s 121us/step - loss: 1.8055 - accuracy: 0.3434 - val_loss: 1.7781 - val_accuracy: 0.3390\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 6s 118us/step - loss: 1.7533 - accuracy: 0.3683 - val_loss: 1.8017 - val_accuracy: 0.3553\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 6s 120us/step - loss: 1.7252 - accuracy: 0.3847 - val_loss: 1.8342 - val_accuracy: 0.3577\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 1.6886 - accuracy: 0.3986 - val_loss: 1.6880 - val_accuracy: 0.4025\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 6s 125us/step - loss: 1.6725 - accuracy: 0.4058 - val_loss: 1.7480 - val_accuracy: 0.3717\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 7s 137us/step - loss: 1.6549 - accuracy: 0.4112 - val_loss: 1.7534 - val_accuracy: 0.3915\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 8s 160us/step - loss: 1.6418 - accuracy: 0.4146 - val_loss: 1.6927 - val_accuracy: 0.4068\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 9s 186us/step - loss: 1.6257 - accuracy: 0.4202 - val_loss: 1.7327 - val_accuracy: 0.3832\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 6s 122us/step - loss: 1.6255 - accuracy: 0.4196 - val_loss: 1.6559 - val_accuracy: 0.3998\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 6s 110us/step - loss: 1.6135 - accuracy: 0.4255 - val_loss: 1.7620 - val_accuracy: 0.3809\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 6s 125us/step - loss: 1.6082 - accuracy: 0.4286 - val_loss: 1.6715 - val_accuracy: 0.4080\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 6s 127us/step - loss: 1.5953 - accuracy: 0.4335 - val_loss: 1.7488 - val_accuracy: 0.3897\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 5s 109us/step - loss: 1.5876 - accuracy: 0.4359 - val_loss: 1.6850 - val_accuracy: 0.4092\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 6s 119us/step - loss: 1.5758 - accuracy: 0.4409 - val_loss: 1.6757 - val_accuracy: 0.4150\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 7s 145us/step - loss: 1.5774 - accuracy: 0.4402 - val_loss: 1.6987 - val_accuracy: 0.3968\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 7s 140us/step - loss: 1.5737 - accuracy: 0.4406 - val_loss: 1.8797 - val_accuracy: 0.3485\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 7s 145us/step - loss: 1.5645 - accuracy: 0.4447 - val_loss: 1.7488 - val_accuracy: 0.4029\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 6s 124us/step - loss: 1.5563 - accuracy: 0.4514 - val_loss: 1.7051 - val_accuracy: 0.4009\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 7s 148us/step - loss: 1.5539 - accuracy: 0.4495 - val_loss: 1.7264 - val_accuracy: 0.4092\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 7s 139us/step - loss: 1.5552 - accuracy: 0.4500 - val_loss: 1.6409 - val_accuracy: 0.4224\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 9s 172us/step - loss: 1.5454 - accuracy: 0.4526 - val_loss: 1.7657 - val_accuracy: 0.4058\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 7s 131us/step - loss: 1.5293 - accuracy: 0.4590 - val_loss: 1.6591 - val_accuracy: 0.4195\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 6s 113us/step - loss: 1.5378 - accuracy: 0.4540 - val_loss: 1.6112 - val_accuracy: 0.4286\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 7s 139us/step - loss: 1.5292 - accuracy: 0.4589 - val_loss: 1.6147 - val_accuracy: 0.4327\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 6s 115us/step - loss: 1.5287 - accuracy: 0.4581 - val_loss: 1.6701 - val_accuracy: 0.4226\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 7s 138us/step - loss: 1.5237 - accuracy: 0.4618 - val_loss: 1.5910 - val_accuracy: 0.4379\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 6s 119us/step - loss: 1.5101 - accuracy: 0.4667 - val_loss: 1.6461 - val_accuracy: 0.4233\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 5s 107us/step - loss: 1.5054 - accuracy: 0.4679 - val_loss: 1.6634 - val_accuracy: 0.4276\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 7s 149us/step - loss: 1.5024 - accuracy: 0.4708 - val_loss: 1.6363 - val_accuracy: 0.4328\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 7s 137us/step - loss: 1.4967 - accuracy: 0.4723 - val_loss: 1.7284 - val_accuracy: 0.4100\n",
      "Epoch 33/50\n",
      "47872/50000 [===========================>..] - ETA: 0s - loss: 1.4927 - accuracy: 0.4719"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-7e116c3851ca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m               \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m               \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m               shuffle=True)\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;31m# Collect results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3738\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3739\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3740\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3741\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3742\u001b[0m     \u001b[0;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1079\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1080\u001b[0m     \"\"\"\n\u001b[0;32m-> 1081\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1082\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1083\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1119\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[1;32m   1120\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[0;32m-> 1121\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1222\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[0;32m-> 1224\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1225\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    512\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "\"\"\"Code Here\n",
    "撰寫你的訓練流程並將結果用 dictionary 紀錄\n",
    "\"\"\"\n",
    "for lr in LEARNING_RATE:\n",
    "    keras.backend.clear_session() # 把舊的 Graph 清掉\n",
    "    print(\"Experiment with LR = %.6f\" % (lr))\n",
    "    model = build_mlp(input_shape=x_train.shape[1:])\n",
    "    model.summary()\n",
    "    optimizer = keras.optimizers.SGD(lr=lr, nesterov=True, momentum=MOMENTUM)\n",
    "    model.compile(loss=\"categorical_crossentropy\", metrics=[\"accuracy\"], optimizer=optimizer)\n",
    "\n",
    "    model.fit(x_train, y_train, \n",
    "              epochs=EPOCHS, \n",
    "              batch_size=BATCH_SIZE, \n",
    "              validation_data=(x_test, y_test), \n",
    "              shuffle=True)\n",
    "    \n",
    "    # Collect results\n",
    "    train_loss = model.history.history[\"loss\"]\n",
    "    valid_loss = model.history.history[\"val_loss\"]\n",
    "    train_acc = model.history.history[\"accuracy\"]\n",
    "    valid_acc = model.history.history[\"val_accuracy\"]\n",
    "    \n",
    "    exp_name_tag = \"exp-lr-%s\" % str(lr)\n",
    "    results[exp_name_tag] = {'train-loss': train_loss,\n",
    "                             'valid-loss': valid_loss,\n",
    "                             'train-acc': train_acc,\n",
    "                             'valid-acc': valid_acc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\"\"\"Code Here\n",
    "將結果繪出\n",
    "\"\"\"\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "color_bar = [\"r\", \"g\", \"b\", \"y\", \"m\", \"k\"]\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "for i, cond in enumerate(results.keys()):\n",
    "    plt.plot(range(len(results[cond]['train-loss'])),results[cond]['train-loss'], '-', label=cond, color=color_bar[i])\n",
    "    plt.plot(range(len(results[cond]['valid-loss'])),results[cond]['valid-loss'], '--', label=cond, color=color_bar[i])\n",
    "plt.title(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "for i, cond in enumerate(results.keys()):\n",
    "    plt.plot(range(len(results[cond]['train-acc'])),results[cond]['train-acc'], '-', label=cond, color=color_bar[i])\n",
    "    plt.plot(range(len(results[cond]['valid-acc'])),results[cond]['valid-acc'], '--', label=cond, color=color_bar[i])\n",
    "plt.title(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Code Here\n",
    "設定超參數\n",
    "\"\"\"\n",
    "LEARNING_RATE = [1e-1, 1e-2, 1e-3, 1e-4, 1e-5]\n",
    "EPOCHS = 50\n",
    "BATCH_SIZE = 256\n",
    "MOMENTUM = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "\"\"\"Code Here\n",
    "撰寫你的訓練流程並將結果用 dictionary 紀錄\n",
    "\"\"\"\n",
    "for lr in LEARNING_RATE:\n",
    "    keras.backend.clear_session() # 把舊的 Graph 清掉\n",
    "    print(\"Experiment with LR = %.6f\" % (lr))\n",
    "    model = build_mlp(input_shape=x_train.shape[1:])\n",
    "    model.summary()\n",
    "    optimizer = keras.optimizers.SGD(lr=lr, nesterov=True, momentum=MOMENTUM)\n",
    "    model.compile(loss=\"categorical_crossentropy\", metrics=[\"accuracy\"], optimizer=optimizer)\n",
    "\n",
    "    model.fit(x_train, y_train, \n",
    "              epochs=EPOCHS, \n",
    "              batch_size=BATCH_SIZE, \n",
    "              validation_data=(x_test, y_test), \n",
    "              shuffle=True)\n",
    "    \n",
    "    # Collect results\n",
    "    train_loss = model.history.history[\"loss\"]\n",
    "    valid_loss = model.history.history[\"val_loss\"]\n",
    "    train_acc = model.history.history[\"acc\"]\n",
    "    valid_acc = model.history.history[\"val_acc\"]\n",
    "    \n",
    "    exp_name_tag = \"exp-lr-%s\" % str(lr)\n",
    "    results[exp_name_tag] = {'train-loss': train_loss,\n",
    "                             'valid-loss': valid_loss,\n",
    "                             'train-acc': train_acc,\n",
    "                             'valid-acc': valid_acc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\"\"\"Code Here\n",
    "將結果繪出\n",
    "\"\"\"\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "color_bar = [\"r\", \"g\", \"b\", \"y\", \"m\", \"k\"]\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "for i, cond in enumerate(results.keys()):\n",
    "    plt.plot(range(len(results[cond]['train-loss'])),results[cond]['train-loss'], '-', label=cond, color=color_bar[i])\n",
    "    plt.plot(range(len(results[cond]['valid-loss'])),results[cond]['valid-loss'], '--', label=cond, color=color_bar[i])\n",
    "plt.title(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "for i, cond in enumerate(results.keys()):\n",
    "    plt.plot(range(len(results[cond]['train-acc'])),results[cond]['train-acc'], '-', label=cond, color=color_bar[i])\n",
    "    plt.plot(range(len(results[cond]['valid-acc'])),results[cond]['valid-acc'], '--', label=cond, color=color_bar[i])\n",
    "plt.title(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
