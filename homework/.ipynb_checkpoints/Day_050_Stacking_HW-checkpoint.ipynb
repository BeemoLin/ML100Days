{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 作業 : (Kaggle)鐵達尼生存預測\n",
    "***\n",
    "- 分數以網站評分結果為準, 請同學實際將提交檔(*.csv)上傳試試看  \n",
    "https://www.kaggle.com/c/titanic/submit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [作業目標]\n",
    "- 試著模仿範例寫法, 在鐵達尼生存預測中, 觀查堆疊泛化 (Stacking) 的寫法與效果"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [作業重點]\n",
    "- 完成堆疊泛化的寫作, 看看提交結果, 想想看 : 分類與回歸的堆疊泛化, 是不是也與混合泛化一樣有所不同呢?(In[14])  \n",
    "如果可能不同, 應該怎麼改寫會有較好的結果?  \n",
    "- Hint : 請參考 mlxtrend 官方網站 StackingClassifier 的頁面說明 : Using Probabilities as Meta-Features\n",
    "http://rasbt.github.io/mlxtend/user_guide/classifier/StackingClassifier/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass                                               Name     Sex   Age  \\\n",
       "0       3                            Braund, Mr. Owen Harris    male  22.0   \n",
       "1       1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0   \n",
       "2       3                             Heikkinen, Miss. Laina  female  26.0   \n",
       "3       1       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0   \n",
       "4       3                           Allen, Mr. William Henry    male  35.0   \n",
       "\n",
       "   SibSp  Parch            Ticket     Fare Cabin Embarked  \n",
       "0      1      0         A/5 21171   7.2500   NaN        S  \n",
       "1      1      0          PC 17599  71.2833   C85        C  \n",
       "2      0      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      1      0            113803  53.1000  C123        S  \n",
       "4      0      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 做完特徵工程前的所有準備 (與前範例相同)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy, time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from IPython.display import display\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "data_path = 'data/'\n",
    "df_train = pd.read_csv(data_path + 'titanic_train.csv')\n",
    "df_test = pd.read_csv(data_path + 'titanic_test.csv')\n",
    "\n",
    "train_Y = df_train['Survived']\n",
    "test_Y = df_test['Survived']\n",
    "ids = df_test['PassengerId']\n",
    "df_train = df_train.drop(['PassengerId', 'Survived'] , axis=1)\n",
    "df_test = df_test.drop(['PassengerId'] , axis=1)\n",
    "df = pd.concat([df_train,df_test])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Missing Ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Cabin</th>\n",
       "      <td>77.463713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>20.091673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Embarked</th>\n",
       "      <td>0.152788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fare</th>\n",
       "      <td>0.076394</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Missing Ratio\n",
       "Cabin         77.463713\n",
       "Age           20.091673\n",
       "Embarked       0.152788\n",
       "Fare           0.076394"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 檢查 DataFrame 空缺值的狀態\n",
    "def na_check(df_data):\n",
    "    data_na = (df_data.isnull().sum() / len(df_data)) * 100\n",
    "    data_na = data_na.drop(data_na[data_na == 0].index).sort_values(ascending=False)\n",
    "    missing_data = pd.DataFrame({'Missing Ratio' :data_na})\n",
    "    display(missing_data.head(10))\n",
    "na_check(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 以下 In[3]~In[10] 只是鐵達尼預測中的一組特徵工程, 並以此組特徵工程跑參數, 若更換其他特徵工程, In[10]的參數需要重新跑\n",
    "# Sex : 直接轉男 0 女 1\n",
    "df[\"Sex\"] = df[\"Sex\"].map({\"male\": 0, \"female\":1})\n",
    "# Fare : 用 log 去偏態, 0 則直接取 0\n",
    "df[\"Fare\"] = df[\"Fare\"].map(lambda i: np.log(i) if i > 0 else 0)\n",
    "# Age : 缺值用中位數補\n",
    "df[\"Age\"] = df[\"Age\"].fillna(df['Age'].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Title 的 特徵工程 : 將各種頭銜按照類型分類, 最後取 One Hot\n",
    "df_title = [i.split(\",\")[1].split(\".\")[0].strip() for i in df[\"Name\"]]\n",
    "df[\"Title\"] = pd.Series(df_title)\n",
    "df[\"Title\"] = df[\"Title\"].replace(['Lady', 'the Countess','Countess','Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n",
    "df[\"Title\"] = df[\"Title\"].map({\"Master\":0, \"Miss\":1, \"Ms\" : 1 , \"Mme\":1, \"Mlle\":1, \"Mrs\":1, \"Mr\":2, \"Rare\":3})\n",
    "df[\"Title\"] = df[\"Title\"].astype(int)\n",
    "df = pd.get_dummies(df, columns = [\"Title\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 新建:家庭大小 (Fsize)特徵, 並依照大小分別建獨立欄位\n",
    "df[\"Fsize\"] = df[\"SibSp\"] + df[\"Parch\"] + 1\n",
    "df['Single'] = df['Fsize'].map(lambda s: 1 if s == 1 else 0)\n",
    "df['SmallF'] = df['Fsize'].map(lambda s: 1 if  s == 2  else 0)\n",
    "df['MedF'] = df['Fsize'].map(lambda s: 1 if 3 <= s <= 4 else 0)\n",
    "df['LargeF'] = df['Fsize'].map(lambda s: 1 if s >= 5 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ticket : 如果不只是數字-取第一個空白之前的字串(去除'.'與'/'), 如果只是數字-設為'X', 最後再取 One Hot\n",
    "Ticket = []\n",
    "for i in list(df.Ticket):\n",
    "    if not i.isdigit() :\n",
    "        Ticket.append(i.replace(\".\",\"\").replace(\"/\",\"\").strip().split(' ')[0])\n",
    "    else:\n",
    "        Ticket.append(\"X\")        \n",
    "df[\"Ticket\"] = Ticket\n",
    "df = pd.get_dummies(df, columns = [\"Ticket\"], prefix=\"T\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cabib 依照第一碼分類, 再取 One Hot\n",
    "df[\"Cabin\"] = pd.Series([i[0] if not pd.isnull(i) else 'X' for i in df['Cabin'] ])\n",
    "df = pd.get_dummies(df, columns = [\"Cabin\"], prefix=\"Cabin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embarked, Pclass 取 One Hot\n",
    "df = pd.get_dummies(df, columns = [\"Embarked\"], prefix=\"Em\")\n",
    "df[\"Pclass\"] = df[\"Pclass\"].astype(\"category\")\n",
    "df = pd.get_dummies(df, columns = [\"Pclass\"], prefix=\"Pc\")\n",
    "\n",
    "# 捨棄 Name 欄位\n",
    "df.drop(labels = [\"Name\"], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Missing Ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Missing Ratio]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Title_0</th>\n",
       "      <th>Title_1</th>\n",
       "      <th>Title_2</th>\n",
       "      <th>Title_3</th>\n",
       "      <th>Fsize</th>\n",
       "      <th>...</th>\n",
       "      <th>Cabin_F</th>\n",
       "      <th>Cabin_G</th>\n",
       "      <th>Cabin_T</th>\n",
       "      <th>Cabin_X</th>\n",
       "      <th>Em_C</th>\n",
       "      <th>Em_Q</th>\n",
       "      <th>Em_S</th>\n",
       "      <th>Pc_1</th>\n",
       "      <th>Pc_2</th>\n",
       "      <th>Pc_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.981001</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.266662</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.070022</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.972177</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.085672</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 66 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sex   Age  SibSp  Parch      Fare  Title_0  Title_1  Title_2  Title_3  \\\n",
       "0    0  22.0      1      0  1.981001        0        0        1        0   \n",
       "1    1  38.0      1      0  4.266662        0        1        0        0   \n",
       "2    1  26.0      0      0  2.070022        0        1        0        0   \n",
       "3    1  35.0      1      0  3.972177        0        1        0        0   \n",
       "4    0  35.0      0      0  2.085672        0        0        1        0   \n",
       "\n",
       "   Fsize  ...  Cabin_F  Cabin_G  Cabin_T  Cabin_X  Em_C  Em_Q  Em_S  Pc_1  \\\n",
       "0      2  ...        0        0        0        1     0     0     1     0   \n",
       "1      2  ...        0        0        0        0     1     0     0     1   \n",
       "2      1  ...        0        0        0        1     0     0     1     0   \n",
       "3      2  ...        0        0        0        0     0     0     1     1   \n",
       "4      1  ...        0        0        0        1     0     0     1     0   \n",
       "\n",
       "   Pc_2  Pc_3  \n",
       "0     0     1  \n",
       "1     0     0  \n",
       "2     0     1  \n",
       "3     0     0  \n",
       "4     0     1  \n",
       "\n",
       "[5 rows x 66 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "na_check(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 將資料最大最小化\n",
    "df = MinMaxScaler().fit_transform(df)\n",
    "\n",
    "# 將前述轉換完畢資料 df , 重新切成 train_X, test_X\n",
    "train_num = train_Y.shape[0]\n",
    "train_X = df[:train_num]\n",
    "test_X = df[train_num:]\n",
    "\n",
    "# 使用三種模型 : 邏輯斯迴歸 / 梯度提升機 / 隨機森林, 參數使用 Random Search 尋找\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "lr = LogisticRegression(tol=0.001, penalty='l2', fit_intercept=True, C=1.0)\n",
    "gdbt = GradientBoostingClassifier(tol=100, subsample=0.75, n_estimators=250, max_features=20,\n",
    "                                  max_depth=6, learning_rate=0.03)\n",
    "rf = RandomForestClassifier(n_estimators=100, min_samples_split=2, min_samples_leaf=1, \n",
    "                            max_features='sqrt', max_depth=6, bootstrap=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 線性迴歸預測檔 (結果有部分隨機, 請以 Kaggle 計算的得分為準, 以下模型同理)\n",
    "lr.fit(train_X, train_Y)\n",
    "lr_pred = lr.predict_proba(test_X)[:,1]\n",
    "sub = pd.DataFrame({'PassengerId': ids, 'Survived': lr_pred})\n",
    "sub['Survived'] = sub['Survived'].map(lambda x:1 if x>0.5 else 0) \n",
    "sub.to_csv('titanic_lr.csv', index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 梯度提升機預測檔 \n",
    "gdbt.fit(train_X, train_Y)\n",
    "gdbt_pred = gdbt.predict_proba(test_X)[:,1]\n",
    "sub = pd.DataFrame({'PassengerId': ids, 'Survived': gdbt_pred})\n",
    "sub['Survived'] = sub['Survived'].map(lambda x:1 if x>0.5 else 0) \n",
    "sub.to_csv('titanic_gdbt.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 隨機森林預測檔\n",
    "rf.fit(train_X, train_Y)\n",
    "rf_pred = rf.predict_proba(test_X)[:,1]\n",
    "sub = pd.DataFrame({'PassengerId': ids, 'Survived': rf_pred})\n",
    "sub['Survived'] = sub['Survived'].map(lambda x:1 if x>0.5 else 0) \n",
    "sub.to_csv('titanic_rf.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 作業\n",
    "* 分類預測的集成泛化, 也與回歸的很不一樣  \n",
    "既然分類的 Blending 要變成機率, 才比較容易集成,\n",
    "那麼分類的 Stacking 要讓第一層的模型輸出機率當特徵, 應該要怎麼寫呢?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3-fold cross validation:\n",
      "\n",
      "Accuracy: 0.82 (+/- 0.01) [LogisticRegression]\n",
      "Accuracy: 0.82 (+/- 0.02) [GradientBoosting]\n",
      "Accuracy: 0.83 (+/- 0.02) [Random Forest]\n",
      "Accuracy: 0.83 (+/- 0.02) [StackingClassifier]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import model_selection\n",
    "from mlxtend.classifier import StackingClassifier\n",
    "\n",
    "meta_estimator = GradientBoostingClassifier(tol=100, subsample=0.70, n_estimators=50, \n",
    "                                           max_features='sqrt', max_depth=4, learning_rate=0.3)\n",
    "\"\"\"\n",
    "Your Code Here\n",
    "\"\"\"\n",
    "# lr, gdbt, rf\n",
    "\n",
    "stacking = StackingClassifier(classifiers=[gdbt, rf], \n",
    "                          meta_classifier=lr)\n",
    "\n",
    "print('3-fold cross validation:\\n')\n",
    "\n",
    "for clf, label in zip([lr, gdbt, rf, stacking], \n",
    "                      ['LogisticRegression', \n",
    "                       'GradientBoosting', \n",
    "                       'Random Forest',\n",
    "                       'StackingClassifier']):\n",
    "\n",
    "    scores = model_selection.cross_val_score(clf, train_X, train_Y, \n",
    "                                              cv=3, scoring='accuracy')\n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\" \n",
    "          % (scores.mean(), scores.std(), label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacking.fit(train_X, train_Y)\n",
    "stacking_pred = stacking.predict(test_X)\n",
    "sub = pd.DataFrame({'PassengerId': ids, 'Survived': stacking_pred})\n",
    "sub.to_csv('titanic_stacking.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "y must be a NumPy array. Found <class 'pandas.core.series.Series'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-a0ac357b93f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_Y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgrd\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrd\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplot_decision_regions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_Y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/mlxtend/plotting/decision_regions.py\u001b[0m in \u001b[0;36mplot_decision_regions\u001b[0;34m(X, y, clf, feature_index, filler_feature_values, filler_feature_ranges, ax, X_highlight, res, zoom_factor, legend, hide_spines, markers, colors, scatter_kwargs, contourf_kwargs, scatter_highlight_kwargs)\u001b[0m\n\u001b[1;32m    130\u001b[0m     \"\"\"\n\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m     \u001b[0mcheck_Xy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_int\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Validate X and y arrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m     \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/mlxtend/utils/checking.py\u001b[0m in \u001b[0;36mcheck_Xy\u001b[0;34m(X, y, y_int)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'X must be a NumPy array. Found %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'y must be a NumPy array. Found %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'int'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: y must be a NumPy array. Found <class 'pandas.core.series.Series'>"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 堆疊泛化預測檔 : 分數會依每次執行略有出入, 但通常 Public Score(競賽中的提交分數) 會再比單模好一些\n",
    "# 雖然 Public Score 有可能比 Blending 分數略差, 但是因為不用依賴仔細調整的權重參數, 競賽結束時的 Private Score, 通常會比 Blending 好\n",
    "# (因為權重依賴於 Public 的分數表現), 這種在未知 / 未曝光資料的預測力提升, 就是我們所謂 \"泛化能力比較好\" 在競賽/專案中的含意\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mlxtend.plotting import plot_decision_regions\n",
    "import matplotlib.gridspec as gridspec\n",
    "import itertools\n",
    "\n",
    "gs = gridspec.GridSpec(2, 2)\n",
    "\n",
    "fig = plt.figure(figsize=(10,8))\n",
    "\n",
    "X_combined_std = np.vstack((train_X, test_X))\n",
    "y_combined = np.hstack((train_Y, y_test))\n",
    "\n",
    "for clf, lab, grd in zip([lr, gdbt, rf, stacking], \n",
    "                         ['LogisticRegression', \n",
    "                          'GradientBoosting', \n",
    "                          'Random Forest',\n",
    "                          'StackingClassifier'],\n",
    "                          itertools.product([0, 1], repeat=2)):\n",
    "\n",
    "    clf.fit(train_X, train_Y)\n",
    "    ax = plt.subplot(gs[grd[0], grd[1]])\n",
    "    fig = plot_decision_regions(X=train_X, y=train_Y, clf=clf)\n",
    "    plt.title(lab)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
